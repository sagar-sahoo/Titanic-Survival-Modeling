{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score \n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumptions: Here, the train dataset has been consider as the entire population data, hence we have divided the data into in-sample(80%) and out-of-sample (20%) data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sagarsahoo/Downloads\n"
     ]
    }
   ],
   "source": [
    "cd Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the shape of the Dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check for distribution of Positive and Negative Class: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Survived Class :  61.61616161616162\n",
      "Survived Class :  38.38383838383838\n"
     ]
    }
   ],
   "source": [
    "print(\"Not Survived Class : \", 100 * train_df.Survived.value_counts()[0] / len(train_df))\n",
    "print(\"Survived Class : \", 100 * train_df.Survived.value_counts()[1] / len(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we check for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Age</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin</td>\n",
       "      <td>687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index    0\n",
       "5        Age  177\n",
       "10     Cabin  687\n",
       "11  Embarked    2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = train_df.isnull().sum().reset_index()\n",
    "missing_df[missing_df[0] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have missing values only in Age, Cabin and Embarked Column. Here I have assumed Cabin as irrelevant to our analysis, so I am dropping the column from our dataframe.\n",
    "\n",
    "And there are 2 rows wherein Embarked Column is missing, and hence we can drop these rows from our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['Cabin'], axis = 1, inplace = True)\n",
    "train_df.dropna(subset=['Embarked'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers: We have used IQR to identify the outliers in Features: \"Age\",\"SibSp\",\"Parch\",\"Fare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection \n",
    "\n",
    "def detect_outliers(df,n,features):\n",
    "    \n",
    "    outlier_indices = []\n",
    "    \n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col],75)\n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        \n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n",
    "        \n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        \n",
    "    # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)        \n",
    "    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
    "    \n",
    "    return multiple_outliers   \n",
    "\n",
    "# detect outliers from Age, SibSp , Parch and Fare\n",
    "Outliers_to_drop = detect_outliers(train_df,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at the outliers in the data and drop them from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>439</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Mark</td>\n",
       "      <td>male</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.00</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>588</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Frolicher-Stehli, Mr. Maxmillian</td>\n",
       "      <td>male</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13567</td>\n",
       "      <td>79.20</td>\n",
       "      <td>B41</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>746</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Crosby, Capt. Edward Gifford</td>\n",
       "      <td>male</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>WE/P 5735</td>\n",
       "      <td>71.00</td>\n",
       "      <td>B22</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.00</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Miss. Mabel Helen</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.00</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Master. Thomas Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Constance Gladys</td>\n",
       "      <td>female</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Mr. George John Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>342</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Miss. Alice Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.00</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>793</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Stella Anna</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>847</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Mr. Douglas Bullen</td>\n",
       "      <td>male</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Dorothy Edith \"Dolly\"</td>\n",
       "      <td>female</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                               Name     Sex  \\\n",
       "438          439         0       1                  Fortune, Mr. Mark    male   \n",
       "587          588         1       1   Frolicher-Stehli, Mr. Maxmillian    male   \n",
       "745          746         0       1       Crosby, Capt. Edward Gifford    male   \n",
       "27            28         0       1     Fortune, Mr. Charles Alexander    male   \n",
       "88            89         1       1         Fortune, Miss. Mabel Helen  female   \n",
       "159          160         0       3         Sage, Master. Thomas Henry    male   \n",
       "180          181         0       3       Sage, Miss. Constance Gladys  female   \n",
       "201          202         0       3                Sage, Mr. Frederick    male   \n",
       "324          325         0       3           Sage, Mr. George John Jr    male   \n",
       "341          342         1       1     Fortune, Miss. Alice Elizabeth  female   \n",
       "792          793         0       3            Sage, Miss. Stella Anna  female   \n",
       "846          847         0       3           Sage, Mr. Douglas Bullen    male   \n",
       "863          864         0       3  Sage, Miss. Dorothy Edith \"Dolly\"  female   \n",
       "\n",
       "      Age  SibSp  Parch     Ticket    Fare        Cabin Embarked  \n",
       "438  64.0      1      4      19950  263.00  C23 C25 C27        S  \n",
       "587  60.0      1      1      13567   79.20          B41        C  \n",
       "745  70.0      1      1  WE/P 5735   71.00          B22        S  \n",
       "27   19.0      3      2      19950  263.00  C23 C25 C27        S  \n",
       "88   23.0      3      2      19950  263.00  C23 C25 C27        S  \n",
       "159   9.0      8      2   CA. 2343   69.55          NaN        S  \n",
       "180  16.0      8      2   CA. 2343   69.55          NaN        S  \n",
       "201  16.0      8      2   CA. 2343   69.55          NaN        S  \n",
       "324  16.0      8      2   CA. 2343   69.55          NaN        S  \n",
       "341  24.0      3      2      19950  263.00  C23 C25 C27        S  \n",
       "792  14.0      8      2   CA. 2343   69.55          NaN        S  \n",
       "846   9.0      8      2   CA. 2343   69.55          NaN        S  \n",
       "863   9.0      8      2   CA. 2343   69.55          NaN        S  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[Outliers_to_drop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove the outliers from our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We impute the missing Age with KNN Algorithm using PClass, SibSp, Parch and Age as the features for KNN. \n",
    "Mean and Median are not accurate to impute here for Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from fancyimpute import KNN\n",
    "#warnings.filterwarnings('ignore')\n",
    "# you have to uninstall numpy and reinstall numpy\n",
    "# you have to install tensorflow for fancyimpute to work\n",
    "\n",
    "missing = KNN(k=1).fit_transform(train_df[['Pclass','SibSp','Parch','Age']])\n",
    "train_df['Age'] = missing[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to confirm, now we dont have any missing values in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, 0]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = train_df.isnull().sum().reset_index()\n",
    "missing_df[missing_df[0] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x138c2d588>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(train_df.corr())\n",
    "#train_df.corr().unstack().sort_values().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005007</td>\n",
       "      <td>-0.035144</td>\n",
       "      <td>0.036847</td>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.012658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>-0.005007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.035144</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.036847</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.096067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PassengerId  Survived    Pclass       Age     SibSp     Parch  \\\n",
       "PassengerId     1.000000 -0.005007 -0.035144  0.036847 -0.057527 -0.001652   \n",
       "Survived       -0.005007  1.000000 -0.338481 -0.077221 -0.035322  0.081629   \n",
       "Pclass         -0.035144 -0.338481  1.000000 -0.369226  0.083081  0.018443   \n",
       "Age             0.036847 -0.077221 -0.369226  1.000000 -0.308247 -0.189119   \n",
       "SibSp          -0.057527 -0.035322  0.083081 -0.308247  1.000000  0.414838   \n",
       "Parch          -0.001652  0.081629  0.018443 -0.189119  0.414838  1.000000   \n",
       "Fare            0.012658  0.257307 -0.549500  0.096067  0.159651  0.216225   \n",
       "\n",
       "                 Fare  \n",
       "PassengerId  0.012658  \n",
       "Survived     0.257307  \n",
       "Pclass      -0.549500  \n",
       "Age          0.096067  \n",
       "SibSp        0.159651  \n",
       "Parch        0.216225  \n",
       "Fare         1.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    train_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This correlation matrix is not to understand the correlation of response with features (as the response is a binary categorical response and features are continuous), rather it is visualize the correlation among the features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could see that SibSp and Parch are highly correlated we introduce a new variable \"family_size\" and then drop both columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"family_size\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[[ 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'family_size']]\n",
    "y = train_df['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now introduce dummy variables for the categorical features:  Embarked, PClass and Sex!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(data=X, columns=['Embarked','Pclass','Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>family_size</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Fare  family_size  Embarked_C  Embarked_Q  Embarked_S  Pclass_1  \\\n",
       "0  22.0   7.2500            2           0           0           1         0   \n",
       "1  38.0  71.2833            2           1           0           0         1   \n",
       "2  26.0   7.9250            1           0           0           1         0   \n",
       "3  35.0  53.1000            2           0           0           1         1   \n",
       "4  35.0   8.0500            1           0           0           1         0   \n",
       "\n",
       "   Pclass_2  Pclass_3  Sex_female  Sex_male  \n",
       "0         0         1           0         1  \n",
       "1         0         0           1         0  \n",
       "2         0         1           1         0  \n",
       "3         0         0           1         0  \n",
       "4         0         1           0         1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scale the feature Age, Fare, family_size using Standard Scaler. Some algorithms use Eucleadian Distance, and hence the reason for scaling features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X['Age']=scaler.fit_transform(X.Age.values.reshape(-1, 1))\n",
    "X['Fare']=scaler.fit_transform(X.Fare.values.reshape(-1, 1))\n",
    "X['family_size']=scaler.fit_transform(X.family_size.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we split the dataset into training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.drop(['Survived'], axis = 1, inplace = True)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>family_size</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1.630678</td>\n",
       "      <td>-0.483457</td>\n",
       "      <td>-0.590563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>-0.537434</td>\n",
       "      <td>-0.482929</td>\n",
       "      <td>-0.590563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>0.210191</td>\n",
       "      <td>-0.494454</td>\n",
       "      <td>-0.590563</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>1.032578</td>\n",
       "      <td>3.815577</td>\n",
       "      <td>0.136028</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>-0.537434</td>\n",
       "      <td>-0.319805</td>\n",
       "      <td>0.136028</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age      Fare  family_size  Embarked_C  Embarked_Q  Embarked_S  \\\n",
       "399  1.630678 -0.483457    -0.590563           0           0           1   \n",
       "546 -0.537434 -0.482929    -0.590563           0           0           1   \n",
       "523  0.210191 -0.494454    -0.590563           1           0           0   \n",
       "769  1.032578  3.815577     0.136028           0           0           1   \n",
       "236 -0.537434 -0.319805     0.136028           0           1           0   \n",
       "\n",
       "     Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  \n",
       "399         0         0         1           0         1  \n",
       "546         0         0         1           1         0  \n",
       "523         0         0         1           0         1  \n",
       "769         1         0         0           1         0  \n",
       "236         0         0         1           1         0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticReg = LogisticRegression()\n",
    "logisticReg.fit(X_train, y_train)\n",
    "#logisticReg.coef_\n",
    "y_pred = logisticReg.predict(X_test)\n",
    "y_pred_proba = logisticReg.predict_proba(X_test)[:, 1]\n",
    "[fpr, tpr, thr] = roc_curve(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression accuracy is 0.761\n",
      "LogisticRegression log_loss is 0.497\n",
      "LogisticRegression auc is 0.817\n"
     ]
    }
   ],
   "source": [
    "print(logisticReg.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_test, y_pred))\n",
    "print(logisticReg.__class__.__name__+\" log_loss is %2.3f\" % log_loss(y_test, y_pred_proba))\n",
    "print(logisticReg.__class__.__name__+\" auc is %2.3f\" % auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification problems, ideally AUC is a good measure. Here we got a score of 0.817 without regularization. Now we use GridSearchCV to run Logistic Regression at various values of C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: LogisticRegression(C=0.20001000000000002, class_weight=None, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "best params: {'C': 0.20001000000000002}\n",
      "best score: 0.8095171026156942\n",
      "0.7613636363636364\n",
      "0.8166666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {'C': np.arange(1e-05, 3, 0.1)}\n",
    "\n",
    "scoring = {'Accuracy': 'accuracy', 'AUC': 'roc_auc', 'Log_loss': 'neg_log_loss'}\n",
    "\n",
    "gs = GridSearchCV(LogisticRegression(), return_train_score=True,\n",
    "                  param_grid=param_grid, scoring=scoring, cv=10, refit='Accuracy')\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "results = gs.cv_results_\n",
    "\n",
    "print(\"best params: \" + str(gs.best_estimator_))\n",
    "print(\"best params: \" + str(gs.best_params_))\n",
    "print('best score:', gs.best_score_)\n",
    "\n",
    "\n",
    "y_pred_proba = logisticReg.predict_proba(X_test)[:, 1]\n",
    "[fpr, tpr, thr] = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV with 10 Fold Cross Validation gave us a AUC of 0.8166 for C = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now try, Polynomial SVM :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC accuracy is 0.756\n",
      "SVC auc is 0.813\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='poly', degree=8,probability=True)\n",
    "svclassifier.fit(X_train, y_train)\n",
    "y_svc_pred = svclassifier.predict(X_test)\n",
    "y_svc_pred_proba = svclassifier.predict_proba(X_test)[:, 1]\n",
    "[fpr_svc, tpr_svc, thr_svc] = roc_curve(y_test, y_svc_pred_proba)\n",
    "print(svclassifier.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_test, y_svc_pred))\n",
    "print(svclassifier.__class__.__name__+\" auc is %2.3f\" % auc(fpr_svc, tpr_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now Gaussian Kernel: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC accuracy is 0.790\n",
      "SVC auc is 0.836\n"
     ]
    }
   ],
   "source": [
    "rbf_svclassifier = SVC(kernel='rbf',probability=True)\n",
    "rbf_svclassifier.fit(X_train, y_train)\n",
    "y_rbf_pred = rbf_svclassifier.predict(X_test)\n",
    "y_rbf_pred_proba = rbf_svclassifier.predict_proba(X_test)[:, 1]\n",
    "[fpr_svc, tpr_svc, thr_svc] = roc_curve(y_test, y_rbf_pred_proba)\n",
    "print(svclassifier.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_test, y_rbf_pred))\n",
    "print(svclassifier.__class__.__name__+\" auc is %2.3f\" % auc(fpr_svc, tpr_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Kernel gave better performance as compared to Polynomial Kernel. We now use GridSearchCV to get the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 75 candidates, totalling 375 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.816, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.738, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.752, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.750, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.757, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n",
      "[CV] ......... C=0.1, gamma=1, kernel=poly, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n",
      "[CV] ......... C=0.1, gamma=1, kernel=poly, score=0.794, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=0.1, gamma=1, kernel=poly, score=0.787, total=   0.1s\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n",
      "[CV] ......... C=0.1, gamma=1, kernel=poly, score=0.800, total=   0.1s\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n",
      "[CV] ......... C=0.1, gamma=1, kernel=poly, score=0.829, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=0.1, gamma=1, kernel=sigmoid, score=0.681, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=0.1, gamma=1, kernel=sigmoid, score=0.688, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=0.1, gamma=1, kernel=sigmoid, score=0.681, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=0.1, gamma=1, kernel=sigmoid, score=0.693, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=0.1, gamma=1, kernel=sigmoid, score=0.643, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.830, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.766, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.759, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.836, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.829, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=0.1, gamma=0.1, kernel=poly, score=0.624, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=0.1, gamma=0.1, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=0.1, gamma=0.1, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=0.1, gamma=0.1, kernel=poly, score=0.643, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=0.1, gamma=0.1, kernel=poly, score=0.650, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=0.1, gamma=0.1, kernel=sigmoid, score=0.809, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=0.1, gamma=0.1, kernel=sigmoid, score=0.730, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=0.1, gamma=0.1, kernel=sigmoid, score=0.752, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=0.1, gamma=0.1, kernel=sigmoid, score=0.829, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=0.1, gamma=0.1, kernel=sigmoid, score=0.821, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.617, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.617, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.610, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.629, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.614, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=0.1, gamma=0.01, kernel=poly, score=0.617, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=0.1, gamma=0.01, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=0.1, gamma=0.01, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=0.1, gamma=0.01, kernel=poly, score=0.614, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=0.1, gamma=0.01, kernel=poly, score=0.614, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=0.1, gamma=0.01, kernel=sigmoid, score=0.617, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=0.1, gamma=0.01, kernel=sigmoid, score=0.610, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=0.1, gamma=0.01, kernel=sigmoid, score=0.610, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=0.1, gamma=0.01, kernel=sigmoid, score=0.614, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=0.1, gamma=0.01, kernel=sigmoid, score=0.621, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.617, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.610, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.610, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.614, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.614, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=poly .................................\n",
      "[CV] ..... C=0.1, gamma=0.001, kernel=poly, score=0.617, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=poly .................................\n",
      "[CV] ..... C=0.1, gamma=0.001, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=poly .................................\n",
      "[CV] ..... C=0.1, gamma=0.001, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=poly .................................\n",
      "[CV] ..... C=0.1, gamma=0.001, kernel=poly, score=0.614, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=poly .................................\n",
      "[CV] ..... C=0.1, gamma=0.001, kernel=poly, score=0.614, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] .. C=0.1, gamma=0.001, kernel=sigmoid, score=0.617, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] .. C=0.1, gamma=0.001, kernel=sigmoid, score=0.610, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] .. C=0.1, gamma=0.001, kernel=sigmoid, score=0.610, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] .. C=0.1, gamma=0.001, kernel=sigmoid, score=0.614, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] .. C=0.1, gamma=0.001, kernel=sigmoid, score=0.614, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.617, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.610, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.610, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.614, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.614, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=poly ................................\n",
      "[CV] .... C=0.1, gamma=0.0001, kernel=poly, score=0.617, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=poly ................................\n",
      "[CV] .... C=0.1, gamma=0.0001, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=poly ................................\n",
      "[CV] .... C=0.1, gamma=0.0001, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=poly ................................\n",
      "[CV] .... C=0.1, gamma=0.0001, kernel=poly, score=0.614, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=poly ................................\n",
      "[CV] .... C=0.1, gamma=0.0001, kernel=poly, score=0.614, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=sigmoid .............................\n",
      "[CV] . C=0.1, gamma=0.0001, kernel=sigmoid, score=0.617, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=sigmoid .............................\n",
      "[CV] . C=0.1, gamma=0.0001, kernel=sigmoid, score=0.610, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=sigmoid .............................\n",
      "[CV] . C=0.1, gamma=0.0001, kernel=sigmoid, score=0.610, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=sigmoid .............................\n",
      "[CV] . C=0.1, gamma=0.0001, kernel=sigmoid, score=0.614, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=sigmoid .............................\n",
      "[CV] . C=0.1, gamma=0.0001, kernel=sigmoid, score=0.614, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.823, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.816, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.787, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.786, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.843, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=poly .......................................\n",
      "[CV] ........... C=1, gamma=1, kernel=poly, score=0.787, total=   0.4s\n",
      "[CV] C=1, gamma=1, kernel=poly .......................................\n",
      "[CV] ........... C=1, gamma=1, kernel=poly, score=0.752, total=   0.2s\n",
      "[CV] C=1, gamma=1, kernel=poly .......................................\n",
      "[CV] ........... C=1, gamma=1, kernel=poly, score=0.787, total=   0.5s\n",
      "[CV] C=1, gamma=1, kernel=poly .......................................\n",
      "[CV] ........... C=1, gamma=1, kernel=poly, score=0.771, total=   1.0s\n",
      "[CV] C=1, gamma=1, kernel=poly .......................................\n",
      "[CV] ........... C=1, gamma=1, kernel=poly, score=0.807, total=   0.5s\n",
      "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
      "[CV] ........ C=1, gamma=1, kernel=sigmoid, score=0.617, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
      "[CV] ........ C=1, gamma=1, kernel=sigmoid, score=0.688, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
      "[CV] ........ C=1, gamma=1, kernel=sigmoid, score=0.667, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
      "[CV] ........ C=1, gamma=1, kernel=sigmoid, score=0.650, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
      "[CV] ........ C=1, gamma=1, kernel=sigmoid, score=0.629, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.837, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.787, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.773, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.843, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.871, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n",
      "[CV] ......... C=1, gamma=0.1, kernel=poly, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n",
      "[CV] ......... C=1, gamma=0.1, kernel=poly, score=0.794, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n",
      "[CV] ......... C=1, gamma=0.1, kernel=poly, score=0.773, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n",
      "[CV] ......... C=1, gamma=0.1, kernel=poly, score=0.836, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n",
      "[CV] ......... C=1, gamma=0.1, kernel=poly, score=0.850, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=1, gamma=0.1, kernel=sigmoid, score=0.738, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=1, gamma=0.1, kernel=sigmoid, score=0.702, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=1, gamma=0.1, kernel=sigmoid, score=0.752, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=1, gamma=0.1, kernel=sigmoid, score=0.771, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=1, gamma=0.1, kernel=sigmoid, score=0.779, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.816, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.730, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.759, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.836, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.829, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ........ C=1, gamma=0.01, kernel=poly, score=0.617, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ........ C=1, gamma=0.01, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ........ C=1, gamma=0.01, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ........ C=1, gamma=0.01, kernel=poly, score=0.621, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ........ C=1, gamma=0.01, kernel=poly, score=0.629, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] ..... C=1, gamma=0.01, kernel=sigmoid, score=0.816, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] ..... C=1, gamma=0.01, kernel=sigmoid, score=0.723, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] ..... C=1, gamma=0.01, kernel=sigmoid, score=0.745, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] ..... C=1, gamma=0.01, kernel=sigmoid, score=0.836, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] ..... C=1, gamma=0.01, kernel=sigmoid, score=0.836, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.624, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.624, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.610, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.643, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.650, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n",
      "[CV] ....... C=1, gamma=0.001, kernel=poly, score=0.617, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n",
      "[CV] ....... C=1, gamma=0.001, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n",
      "[CV] ....... C=1, gamma=0.001, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n",
      "[CV] ....... C=1, gamma=0.001, kernel=poly, score=0.614, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n",
      "[CV] ....... C=1, gamma=0.001, kernel=poly, score=0.614, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] .... C=1, gamma=0.001, kernel=sigmoid, score=0.617, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] .... C=1, gamma=0.001, kernel=sigmoid, score=0.610, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] .... C=1, gamma=0.001, kernel=sigmoid, score=0.610, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] .... C=1, gamma=0.001, kernel=sigmoid, score=0.614, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] .... C=1, gamma=0.001, kernel=sigmoid, score=0.621, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.617, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.610, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.610, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.614, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.614, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=poly ..................................\n",
      "[CV] ...... C=1, gamma=0.0001, kernel=poly, score=0.617, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=poly ..................................\n",
      "[CV] ...... C=1, gamma=0.0001, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=poly ..................................\n",
      "[CV] ...... C=1, gamma=0.0001, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=poly ..................................\n",
      "[CV] ...... C=1, gamma=0.0001, kernel=poly, score=0.614, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=poly ..................................\n",
      "[CV] ...... C=1, gamma=0.0001, kernel=poly, score=0.614, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=sigmoid ...............................\n",
      "[CV] ... C=1, gamma=0.0001, kernel=sigmoid, score=0.617, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=sigmoid ...............................\n",
      "[CV] ... C=1, gamma=0.0001, kernel=sigmoid, score=0.610, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=sigmoid ...............................\n",
      "[CV] ... C=1, gamma=0.0001, kernel=sigmoid, score=0.610, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=sigmoid ...............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... C=1, gamma=0.0001, kernel=sigmoid, score=0.614, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=sigmoid ...............................\n",
      "[CV] ... C=1, gamma=0.0001, kernel=sigmoid, score=0.614, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.801, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.773, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.787, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.764, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.793, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=poly ......................................\n",
      "[CV] .......... C=10, gamma=1, kernel=poly, score=0.773, total=   2.7s\n",
      "[CV] C=10, gamma=1, kernel=poly ......................................\n",
      "[CV] .......... C=10, gamma=1, kernel=poly, score=0.709, total=   0.9s\n",
      "[CV] C=10, gamma=1, kernel=poly ......................................\n",
      "[CV] .......... C=10, gamma=1, kernel=poly, score=0.787, total=   1.6s\n",
      "[CV] C=10, gamma=1, kernel=poly ......................................\n",
      "[CV] .......... C=10, gamma=1, kernel=poly, score=0.764, total=   3.5s\n",
      "[CV] C=10, gamma=1, kernel=poly ......................................\n",
      "[CV] .......... C=10, gamma=1, kernel=poly, score=0.800, total=   2.9s\n",
      "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
      "[CV] ....... C=10, gamma=1, kernel=sigmoid, score=0.638, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
      "[CV] ....... C=10, gamma=1, kernel=sigmoid, score=0.681, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
      "[CV] ....... C=10, gamma=1, kernel=sigmoid, score=0.660, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
      "[CV] ....... C=10, gamma=1, kernel=sigmoid, score=0.686, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
      "[CV] ....... C=10, gamma=1, kernel=sigmoid, score=0.629, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.823, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.809, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.787, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.807, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.857, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n",
      "[CV] ........ C=10, gamma=0.1, kernel=poly, score=0.816, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n",
      "[CV] ........ C=10, gamma=0.1, kernel=poly, score=0.801, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n",
      "[CV] ........ C=10, gamma=0.1, kernel=poly, score=0.787, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n",
      "[CV] ........ C=10, gamma=0.1, kernel=poly, score=0.807, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n",
      "[CV] ........ C=10, gamma=0.1, kernel=poly, score=0.850, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
      "[CV] ..... C=10, gamma=0.1, kernel=sigmoid, score=0.667, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
      "[CV] ..... C=10, gamma=0.1, kernel=sigmoid, score=0.766, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
      "[CV] ..... C=10, gamma=0.1, kernel=sigmoid, score=0.752, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
      "[CV] ..... C=10, gamma=0.1, kernel=sigmoid, score=0.750, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
      "[CV] ..... C=10, gamma=0.1, kernel=sigmoid, score=0.679, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.823, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.745, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.773, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.836, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.836, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] ....... C=10, gamma=0.01, kernel=poly, score=0.617, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] ....... C=10, gamma=0.01, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] ....... C=10, gamma=0.01, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] ....... C=10, gamma=0.01, kernel=poly, score=0.621, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] ....... C=10, gamma=0.01, kernel=poly, score=0.629, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
      "[CV] .... C=10, gamma=0.01, kernel=sigmoid, score=0.809, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
      "[CV] .... C=10, gamma=0.01, kernel=sigmoid, score=0.723, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
      "[CV] .... C=10, gamma=0.01, kernel=sigmoid, score=0.738, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
      "[CV] .... C=10, gamma=0.01, kernel=sigmoid, score=0.829, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
      "[CV] .... C=10, gamma=0.01, kernel=sigmoid, score=0.821, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.816, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.730, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.759, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.829, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.829, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV] ...... C=10, gamma=0.001, kernel=poly, score=0.617, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV] ...... C=10, gamma=0.001, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV] ...... C=10, gamma=0.001, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV] ...... C=10, gamma=0.001, kernel=poly, score=0.614, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV] ...... C=10, gamma=0.001, kernel=poly, score=0.614, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV] ... C=10, gamma=0.001, kernel=sigmoid, score=0.816, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV] ... C=10, gamma=0.001, kernel=sigmoid, score=0.730, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV] ... C=10, gamma=0.001, kernel=sigmoid, score=0.745, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV] ... C=10, gamma=0.001, kernel=sigmoid, score=0.836, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV] ... C=10, gamma=0.001, kernel=sigmoid, score=0.836, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.617, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.624, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.610, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.643, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.650, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n",
      "[CV] ..... C=10, gamma=0.0001, kernel=poly, score=0.617, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n",
      "[CV] ..... C=10, gamma=0.0001, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n",
      "[CV] ..... C=10, gamma=0.0001, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n",
      "[CV] ..... C=10, gamma=0.0001, kernel=poly, score=0.614, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=poly .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=10, gamma=0.0001, kernel=poly, score=0.614, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=sigmoid ..............................\n",
      "[CV] .. C=10, gamma=0.0001, kernel=sigmoid, score=0.617, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=sigmoid ..............................\n",
      "[CV] .. C=10, gamma=0.0001, kernel=sigmoid, score=0.610, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=sigmoid ..............................\n",
      "[CV] .. C=10, gamma=0.0001, kernel=sigmoid, score=0.610, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=sigmoid ..............................\n",
      "[CV] .. C=10, gamma=0.0001, kernel=sigmoid, score=0.614, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=sigmoid ..............................\n",
      "[CV] .. C=10, gamma=0.0001, kernel=sigmoid, score=0.621, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.773, total=   0.1s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.766, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.766, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.779, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.764, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=poly .....................................\n",
      "[CV] ......... C=100, gamma=1, kernel=poly, score=0.766, total=  34.9s\n",
      "[CV] C=100, gamma=1, kernel=poly .....................................\n",
      "[CV] ......... C=100, gamma=1, kernel=poly, score=0.695, total=  13.0s\n",
      "[CV] C=100, gamma=1, kernel=poly .....................................\n",
      "[CV] ......... C=100, gamma=1, kernel=poly, score=0.801, total=  19.5s\n",
      "[CV] C=100, gamma=1, kernel=poly .....................................\n",
      "[CV] ......... C=100, gamma=1, kernel=poly, score=0.757, total=  38.3s\n",
      "[CV] C=100, gamma=1, kernel=poly .....................................\n",
      "[CV] ......... C=100, gamma=1, kernel=poly, score=0.807, total=  34.0s\n",
      "[CV] C=100, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=100, gamma=1, kernel=sigmoid, score=0.652, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=100, gamma=1, kernel=sigmoid, score=0.702, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=100, gamma=1, kernel=sigmoid, score=0.660, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=100, gamma=1, kernel=sigmoid, score=0.679, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=100, gamma=1, kernel=sigmoid, score=0.629, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.816, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.773, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.809, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.800, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.836, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=100, gamma=0.1, kernel=poly, score=0.794, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=100, gamma=0.1, kernel=poly, score=0.794, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=100, gamma=0.1, kernel=poly, score=0.787, total=   0.1s\n",
      "[CV] C=100, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=100, gamma=0.1, kernel=poly, score=0.800, total=   0.1s\n",
      "[CV] C=100, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=100, gamma=0.1, kernel=poly, score=0.829, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=100, gamma=0.1, kernel=sigmoid, score=0.624, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=100, gamma=0.1, kernel=sigmoid, score=0.674, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=100, gamma=0.1, kernel=sigmoid, score=0.752, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=100, gamma=0.1, kernel=sigmoid, score=0.693, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=100, gamma=0.1, kernel=sigmoid, score=0.671, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.844, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.780, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.773, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.829, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.864, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=100, gamma=0.01, kernel=poly, score=0.624, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=100, gamma=0.01, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=100, gamma=0.01, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=100, gamma=0.01, kernel=poly, score=0.643, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=100, gamma=0.01, kernel=poly, score=0.650, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=100, gamma=0.01, kernel=sigmoid, score=0.801, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=100, gamma=0.01, kernel=sigmoid, score=0.730, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=100, gamma=0.01, kernel=sigmoid, score=0.745, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=100, gamma=0.01, kernel=sigmoid, score=0.821, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=100, gamma=0.01, kernel=sigmoid, score=0.821, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.816, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.730, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.759, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.829, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.829, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=poly .................................\n",
      "[CV] ..... C=100, gamma=0.001, kernel=poly, score=0.617, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=poly .................................\n",
      "[CV] ..... C=100, gamma=0.001, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=poly .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=100, gamma=0.001, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=poly .................................\n",
      "[CV] ..... C=100, gamma=0.001, kernel=poly, score=0.614, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=poly .................................\n",
      "[CV] ..... C=100, gamma=0.001, kernel=poly, score=0.614, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] .. C=100, gamma=0.001, kernel=sigmoid, score=0.816, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] .. C=100, gamma=0.001, kernel=sigmoid, score=0.730, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] .. C=100, gamma=0.001, kernel=sigmoid, score=0.759, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] .. C=100, gamma=0.001, kernel=sigmoid, score=0.829, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] .. C=100, gamma=0.001, kernel=sigmoid, score=0.829, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.816, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.730, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.759, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.829, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.829, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=poly ................................\n",
      "[CV] .... C=100, gamma=0.0001, kernel=poly, score=0.617, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=poly ................................\n",
      "[CV] .... C=100, gamma=0.0001, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=poly ................................\n",
      "[CV] .... C=100, gamma=0.0001, kernel=poly, score=0.610, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=poly ................................\n",
      "[CV] .... C=100, gamma=0.0001, kernel=poly, score=0.614, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=poly ................................\n",
      "[CV] .... C=100, gamma=0.0001, kernel=poly, score=0.614, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=sigmoid .............................\n",
      "[CV] . C=100, gamma=0.0001, kernel=sigmoid, score=0.816, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=sigmoid .............................\n",
      "[CV] . C=100, gamma=0.0001, kernel=sigmoid, score=0.730, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=sigmoid .............................\n",
      "[CV] . C=100, gamma=0.0001, kernel=sigmoid, score=0.745, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=sigmoid .............................\n",
      "[CV] . C=100, gamma=0.0001, kernel=sigmoid, score=0.836, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=sigmoid .............................\n",
      "[CV] . C=100, gamma=0.0001, kernel=sigmoid, score=0.836, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.780, total=   0.5s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.730, total=   0.1s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.752, total=   0.1s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.771, total=   0.1s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.771, total=   0.1s\n",
      "[CV] C=1000, gamma=1, kernel=poly ....................................\n",
      "[CV] ........ C=1000, gamma=1, kernel=poly, score=0.787, total= 3.2min\n",
      "[CV] C=1000, gamma=1, kernel=poly ....................................\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf','poly','sigmoid']}  \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train) \n",
    "\n",
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(grid.best_estimator_)\n",
    "\n",
    "grid_predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score:  0.9771428571428571\n",
      "Test Score:  0.7670454545454546\n"
     ]
    }
   ],
   "source": [
    "print('Training Score: ',clf.score(X_train, y_train))\n",
    "print('Test Score: ',clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree AUC:  0.7547409188034189\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "clf_pred_proba = clf.predict_proba(X_test)\n",
    "print ('Decision Tree AUC: ',roc_auc_score(y_test, clf_pred_proba[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we got an AUC Score of 0.75 with default hyperparameters. Now, we go for GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8385714285714286\n",
      "{'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 2}\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
      "                       max_depth=4, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=0, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "dtc = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# Define the parameter values that should be searched\n",
    "\n",
    "param_grid = {'criterion':('gini', 'entropy'), 'max_depth':[4,6,8,12],\n",
    "              'min_samples_split':list(range(2, 100))}\n",
    "\n",
    "# instantiate the grid\n",
    "grid = GridSearchCV(dtc, param_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "# fit the grid with data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# examine the best model\n",
    "\n",
    "# Single best score achieved across all params (min_samples_split)\n",
    "print(grid.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (min_samples_split) used to generate that score\n",
    "print(grid.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score:  0.7752808988764045\n"
     ]
    }
   ],
   "source": [
    "print('Test Score: ',grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Decision Tree AUC:  0.8362045940170941\n"
     ]
    }
   ],
   "source": [
    "clf_gv_pred_proba = grid.predict_proba(X_test)\n",
    "print ('GridSearch Decision Tree AUC: ',roc_auc_score(y_test, clf_gv_pred_proba[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7840909090909091"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_best = RandomForestClassifier(n_jobs= 1, max_depth=3,random_state=2018 , criterion='entropy', \n",
    "                             n_estimators= 20, verbose=False)\n",
    "rfc_best.fit(X_train,y_train)\n",
    "rfc_best.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7840909090909091"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rfc_pred = rfc_best.predict(X_test)\n",
    "accuracy_score(y_test, y_rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8471428571428572\n",
      "{'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 2, 'n_estimators': 30}\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='entropy', max_depth=8, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=30,\n",
      "                       n_jobs=None, oob_score=False, random_state=2018,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.7556818181818182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "dtc = RandomForestClassifier(random_state=2018)\n",
    "\n",
    "# Define the parameter values that should be searched\n",
    "\n",
    "param_grid = {'criterion':('gini', 'entropy'), 'max_depth':[4,6,8,12],'n_estimators':[10,20,30,40],\n",
    "              'min_samples_split':list(range(2, 100))}\n",
    "\n",
    "# instantiate the grid\n",
    "rf_grid = GridSearchCV(dtc, param_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "# fit the grid with data\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# examine the best model\n",
    "\n",
    "# Single best score achieved across all params (min_samples_split)\n",
    "print(rf_grid.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (min_samples_split) used to generate that score\n",
    "print(rf_grid.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(rf_grid.best_estimator_)\n",
    "\n",
    "print(rf_grid.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Random Forest Accuracy Score  0.7556818181818182\n",
      "GridSearch Decision Tree AUC:  0.8414129273504273\n"
     ]
    }
   ],
   "source": [
    "y_rf_pred= rf_grid.predict(X_test)\n",
    "print('GridSearch Random Forest Accuracy Score ',accuracy_score(y_test, y_rf_pred))\n",
    "\n",
    "rf_gv_pred_proba = rf_grid.predict_proba(X_test)\n",
    "print ('GridSearch Decision Tree AUC: ',roc_auc_score(y_test, rf_gv_pred_proba[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "neighbors = list(range(1, 50, 2))\n",
    "k_accuracy={}\n",
    "\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_knn_pred = knn.predict(X_test)\n",
    "    k_accuracy[k]=( metrics.accuracy_score(y_test, y_knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.7329545454545454,\n",
       " 3: 0.7727272727272727,\n",
       " 5: 0.7556818181818182,\n",
       " 7: 0.75,\n",
       " 9: 0.7613636363636364,\n",
       " 11: 0.7556818181818182,\n",
       " 13: 0.7613636363636364,\n",
       " 15: 0.75,\n",
       " 17: 0.75,\n",
       " 19: 0.7443181818181818,\n",
       " 21: 0.75,\n",
       " 23: 0.7443181818181818,\n",
       " 25: 0.75,\n",
       " 27: 0.7386363636363636,\n",
       " 29: 0.7329545454545454,\n",
       " 31: 0.7613636363636364,\n",
       " 33: 0.7556818181818182,\n",
       " 35: 0.7556818181818182,\n",
       " 37: 0.7556818181818182,\n",
       " 39: 0.7556818181818182,\n",
       " 41: 0.7386363636363636,\n",
       " 43: 0.7329545454545454,\n",
       " 45: 0.7329545454545454,\n",
       " 47: 0.7386363636363636,\n",
       " 49: 0.7386363636363636}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy Score :  0.7613636363636364\n",
      "GridSearch KNN AUC:  0.8247863247863247\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=31)\n",
    "knn.fit(X_train, y_train)\n",
    "y_knn_pred = knn.predict(X_test)\n",
    "print('KNN Accuracy Score : ' ,metrics.accuracy_score(y_test, y_knn_pred))\n",
    "\n",
    "\n",
    "knn_pred_proba = knn.predict_proba(X_test)\n",
    "print ('GridSearch KNN AUC: ',roc_auc_score(y_test, knn_pred_proba[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  50 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=2)]: Done 350 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=2)]: Done 717 out of 720 | elapsed:   45.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=2)]: Done 720 out of 720 | elapsed:   46.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Gradient Boosting Accuracy Score :  0.7840909090909091\n",
      "GridSearch Gradient Boosting AUC:  0.8345352564102564\n"
     ]
    }
   ],
   "source": [
    "GBC = GradientBoostingClassifier()\n",
    "gb_param_grid = {'loss' : [\"deviance\"],\n",
    "              'n_estimators' : [100,200,300],\n",
    "              'learning_rate': [0.1, 0.05, 0.01],\n",
    "              'max_depth': [4, 8],\n",
    "              'min_samples_leaf': [100,150],\n",
    "              'max_features': [0.3, 0.1] \n",
    "              }\n",
    "\n",
    "gsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=10, scoring=\"accuracy\", n_jobs= 2, verbose = 1)\n",
    "\n",
    "gsGBC.fit(X_train,y_train)\n",
    "\n",
    "GBC_best = gsGBC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsGBC.best_score_\n",
    "\n",
    "y_gbc_pred=gsGBC.predict(X_test)\n",
    "\n",
    "print('GridSearch Gradient Boosting Accuracy Score : ' ,metrics.accuracy_score(y_test, y_gbc_pred))\n",
    "\n",
    "\n",
    "gb_pred_proba = gsGBC.predict_proba(X_test)\n",
    "print ('GridSearch Gradient Boosting AUC: ',roc_auc_score(y_test, gb_pred_proba[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost\n",
    "\n",
    "https://mccormickml.com/2013/12/13/adaboost-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 112 candidates, totalling 1120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done 330 tasks      | elapsed:    3.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch AdaBoost Accuracy Score :  0.7556818181818182\n",
      "GridSearch Gradient Boosting AUC:  0.7441239316239316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 1120 out of 1120 | elapsed:    7.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Adaboost\n",
    "DTC = DecisionTreeClassifier()\n",
    "adaDTC = AdaBoostClassifier(DTC)\n",
    "\n",
    "ada_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "              \"base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "              \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n",
    "              \"n_estimators\" :[1,2],\n",
    "              \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\n",
    "\n",
    "gsadaDTC = GridSearchCV(adaDTC,param_grid = ada_param_grid, cv=10, scoring=\"accuracy\", n_jobs= 2, verbose = 1)\n",
    "\n",
    "gsadaDTC.fit(X_train,y_train)\n",
    "\n",
    "ada_best = gsadaDTC.best_estimator_\n",
    "\n",
    "y_ada_pred=gsadaDTC.predict(X_test)\n",
    "\n",
    "print('GridSearch AdaBoost Accuracy Score : ' ,metrics.accuracy_score(y_test, y_ada_pred))\n",
    "\n",
    "\n",
    "adb_pred_proba = gsadaDTC.predict_proba(X_test)\n",
    "\n",
    "print ('GridSearch Gradient Boosting AUC: ',roc_auc_score(y_test, adb_pred_proba[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:   57.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8414285714285714\n",
      "GridSearch ExtraTrees Accuracy Score :  0.7670454545454546\n",
      "GridSearch Gradient Boosting AUC:  0.8278579059829061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 540 out of 540 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "#ExtraTrees \n",
    "ExtC = ExtraTreesClassifier()\n",
    "\n",
    "\n",
    "## Search grid for optimal parameters\n",
    "ex_param_grid = {\"max_depth\": [None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [False],\n",
    "              \"n_estimators\" :[100,300],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "\n",
    "gsExtC = GridSearchCV(ExtC,param_grid = ex_param_grid, cv=10, scoring=\"accuracy\", n_jobs= 2, verbose = 1)\n",
    "\n",
    "gsExtC.fit(X_train,y_train)\n",
    "\n",
    "ExtC_best = gsExtC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "print(gsExtC.best_score_)\n",
    "\n",
    "y_ExtC_pred=gsExtC.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('GridSearch ExtraTrees Accuracy Score : ' ,metrics.accuracy_score(y_test, y_ExtC_pred))\n",
    "\n",
    "\n",
    "extc_pred_proba = gsExtC.predict_proba(X_test)\n",
    "\n",
    "print ('GridSearch Gradient Boosting AUC: ',roc_auc_score(y_test, extc_pred_proba[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xtreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'n_estimators': 14, 'max_depth': 6, 'learning_rate': 0.6, 'colsample_bytree': 0.9}\n",
      "Best accuracy found:  0.8401826484018264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    4.2s finished\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create the parameter grid: gbm_param_grid \n",
    "gbm_param_grid = {\n",
    "    'n_estimators': range(8, 20),\n",
    "    'max_depth': range(6, 10),\n",
    "    'learning_rate': [.4, .45, .5, .55, .6],\n",
    "    'colsample_bytree': [.6, .7, .8, .9, 1]\n",
    "}\n",
    "\n",
    "# Instantiate the regressor: gbm\n",
    "gbm = xgb.XGBClassifier(n_estimators=10)\n",
    "\n",
    "# Perform random search: grid_mse\n",
    "xgb_random = RandomizedSearchCV(param_distributions=gbm_param_grid, \n",
    "                                    estimator = gbm, scoring = \"accuracy\", \n",
    "                                    verbose = 1, n_iter = 50, cv = 4)\n",
    "\n",
    "\n",
    "# Fit randomized_mse to the data\n",
    "xgb_random.fit(X, y)\n",
    "\n",
    "# Print the best parameters and lowest RMSE\n",
    "print(\"Best parameters found: \", xgb_random.best_params_)\n",
    "print(\"Best accuracy found: \", xgb_random.best_score_)\n",
    "\n",
    "\n",
    "y_xgb_pred = xgb_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch XGB Accuracy Score :  0.9147727272727273\n",
      "GridSearch XGB AUC:  0.9734241452991453\n"
     ]
    }
   ],
   "source": [
    "print('GridSearch XGB Accuracy Score : ' ,metrics.accuracy_score(y_test, y_xgb_pred))\n",
    "xgb_pred_proba = xgb_random.predict_proba(X_test)\n",
    "\n",
    "print ('GridSearch XGB AUC: ',roc_auc_score(y_test, xgb_pred_proba[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrows = ncols = 2\n",
    "fig, axes = plt.subplots(nrows = nrows, ncols = ncols, sharex=\"all\", figsize=(15,15))\n",
    "\n",
    "names_classifiers = [(\"AdaBoosting\", gsadaDTC.best_estimator_),(\"ExtraTrees\",gsExtC.best_estimator_),\n",
    "                     (\"RandomForest\",rf_grid.best_estimator_),(\"XtremeGradientBoosting\",xgb_random.best_estimator_)\n",
    "                    ,(\"XtremeGradientBoosting\",gsGBC.best_estimator_)\n",
    "                    ]\n",
    "\n",
    "nclassifier = 0\n",
    "for row in range(nrows):\n",
    "    for col in range(ncols):\n",
    "        name = names_classifiers[nclassifier][0]\n",
    "        classifier = names_classifiers[nclassifier][1]\n",
    "        indices = np.argsort(classifier.feature_importances_)[::-1][:40]\n",
    "        g = sns.barplot(y=X_train.columns[indices][:40],x = classifier.feature_importances_[indices][:40] , orient='h',ax=axes[row][col])\n",
    "        g.set_xlabel(\"Relative importance\",fontsize=12)\n",
    "        g.set_ylabel(\"Features\",fontsize=12)\n",
    "        g.tick_params(labelsize=9)\n",
    "        g.set_title(name + \" feature importance\")\n",
    "        nclassifier += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xtreme Gradient Boosting gave us the highest AUC. ANd the corresponding features (important to the model predictons) are Sex_female, Pclass_3, Pclass_1, Family SIze and Embarked_S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
